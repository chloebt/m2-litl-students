{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP4_PART1_masterLiTL_2122.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCHhtzOXQ2po"
      },
      "source": [
        "# TP 4: Training a Feedforward neural network\n",
        "Master LiTL - 2021-2022\n",
        "\n",
        "## Requirements\n",
        "In this section, we will investigate variations of the setting and the hyper-parameter values of a feedforward NN, still on sentiment analysis on a French dataset of reviews.\n",
        "Our goal is to find the best model for the task, we will thus make use of the development set this time! \n",
        "\n",
        "We will explore:    \n",
        "* varied architectures\n",
        "* varied optimizers\n",
        "* varied activation functions\n",
        "* varied values for the hyper-parameters\n",
        "\n",
        "And in the part 2:\n",
        "* varied representation: sparse and continuous bag-of-words\n",
        "* Add plots of cost function\n",
        "* Add plots of number of training examples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT7n30VpCOzF"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If you’re using Colab, allocate a GPU by going to Edit > Notebook Settings.\n",
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"GPU ok\")\n",
        "else:\n",
        "  print(\"no gpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSyhJqpVczO"
      },
      "source": [
        "\n",
        "## 1. Code for running a FFNN\n",
        "\n",
        "### 1.1 Read the data\n",
        "\n",
        "The code below is the same as last time: the input is a BoW representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoVJ18s_oxkn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "train_path = \"allocine_train.tsv\"\n",
        "dev_path = \"allocine_dev.tsv\"\n",
        "test_path = \"allocine_test.tsv\"\n",
        "\n",
        "# This will be the size of the vectors reprensenting the input\n",
        "MAX_FEATURES = 5000 \n",
        "\n",
        "# Load train set\n",
        "train_df = pd.read_csv(train_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "    \n",
        "# -- VECTORIZE\n",
        "print(\"Creating features from bag of words...\")  \n",
        "vectorizer = CountVectorizer( analyzer = \"word\", max_features = MAX_FEATURES ) \n",
        "train_data_features = vectorizer.fit_transform(train_df[\"review\"])\n",
        "# -- TO DENSE\n",
        "x_train = train_data_features.toarray()\n",
        "y_train = np.asarray(train_df[\"sentiment\"])\n",
        "print( \"TRAIN:\", x_train.shape )\n",
        "\n",
        "dev_df = pd.read_csv(dev_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "dev_data_features = vectorizer.transform(dev_df[\"review\"])\n",
        "x_dev = dev_data_features.toarray()\n",
        "y_dev = np.asarray(dev_df[\"sentiment\"])\n",
        "print( \"DEV:\", x_dev.shape )\n",
        "\n",
        "test_df = pd.read_csv(test_path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "test_data_features = vectorizer.transform(test_df[\"review\"])\n",
        "x_test = test_data_features.toarray()\n",
        "y_test = np.asarray(test_df[\"sentiment\"])\n",
        "print( \"TEST:\", x_test.shape )\n",
        "\n",
        "count_train = x_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Load the data\n",
        "\n",
        "Note that batch size is chosen here."
      ],
      "metadata": {
        "id": "NKM4vI_bny7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data into TENSORS\n",
        "\n",
        "def load_data( x_train, y_train, x_dev, y_dev, x_test, y_test, batch_size=1 ):\n",
        "    #batch_size = 1 # == no batch\n",
        "    # create Tensor dataset\n",
        "    train_data = TensorDataset(torch.from_numpy(x_train).to(torch.float), torch.from_numpy(y_train))\n",
        "\n",
        "    # dataloaders\n",
        "    # make sure to SHUFFLE your data\n",
        "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "    \n",
        "    # Don t need batch at test time\n",
        "    dev_data = TensorDataset(torch.from_numpy(x_dev).to(torch.float), torch.from_numpy(y_dev))\n",
        "    dev_loader = DataLoader(dev_data, shuffle=True, batch_size=1)\n",
        "\n",
        "    test_data = TensorDataset(torch.from_numpy(x_test).to(torch.float), torch.from_numpy(y_test))\n",
        "    test_loader = DataLoader(test_data, shuffle=True, batch_size=1)\n",
        "\n",
        "    return train_loader, dev_loader, test_loader"
      ],
      "metadata": {
        "id": "VDZsMXoUnyCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOeZCY09o6CV"
      },
      "source": [
        "### 1.3 Neural Network Definition\n",
        "\n",
        "Now we can build our learning model.\n",
        "\n",
        "▶▶**What are the elements that can be changed here?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvmc-_zqoxvF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
        "        # just always do it in an nn.Module\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "\n",
        "        # Define the parameters that you will need. \n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function  # LINEAR\n",
        "        out = self.fc1(x)\n",
        "\n",
        "        # Non-linearity  # NON-LINEAR\n",
        "        out = self.sigmoid(out) \n",
        "\n",
        "        # Linear function (readout)  # LINEAR\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Training function\n",
        "\n",
        "Below, the code for a function that trains a model.\n",
        "\n",
        "▶▶**What are the elements that can be changed here?**"
      ],
      "metadata": {
        "id": "DVrIvVbjoxU4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnNx8hZJox3v"
      },
      "source": [
        "# TRAINING\n",
        "def train( model, train_loader, optimizer, num_epochs=5 ):\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, total_acc, total_count = 0, 0, 0\n",
        "        for input, label in train_loader:\n",
        "            # Step1. Clearing the accumulated gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Step 2. Forward pass to get output/logits\n",
        "            outputs = model( input )\n",
        "\n",
        "            # Step 3. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            # - Calculate Loss: softmax --> cross entropy loss\n",
        "            loss = criterion(outputs, label)\n",
        "            # - Getting gradients w.r.t. parameters\n",
        "            loss.backward()\n",
        "            # - Updating parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accumulating the loss over time\n",
        "            train_loss += loss.item()\n",
        "            total_acc += (outputs.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "\n",
        "        # Compute accuracy on train set at each epoch\n",
        "        print('Epoch: {}. Loss: {}. ACC {} '.format(epoch, train_loss/count_train, total_acc/count_train))\n",
        "        \n",
        "        total_acc, total_count = 0, 0\n",
        "        train_loss = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQRgrMEael9W"
      },
      "source": [
        "### 1.5 Evaluation\n",
        "\n",
        "Below you have the code for a function that can be used to evaluate the model: it prints the classification report and return the gold and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldDubAPDox5K"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "def evaluate( model, dev_loader ):\n",
        "    predictions = []\n",
        "    gold = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input, label in dev_loader:\n",
        "            probs = model(input)\n",
        "            predictions.append( torch.argmax(probs, dim=1).cpu().numpy()[0] )\n",
        "            gold.append(int(label))\n",
        "\n",
        "    print(classification_report(gold, predictions))\n",
        "    return gold, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Runing an experiment\n",
        "\n",
        "Below a function that could be used to save the results, don't hesitate to write your own or modify it."
      ],
      "metadata": {
        "id": "eGJ2WtzFpKgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Save the scores and settings\n",
        "my_expe = 'scores_ffnn_bow.txt'\n",
        "\n",
        "def write_expe_settings( my_file, batch=1, hidden=1, hsize=4, act='sigmoid', lr=0.1, opt='sgd', epochs=5, score=0. ):\n",
        "  with open( my_file, 'a' ) as f:\n",
        "    f.write( 'batch:{batch}\\thidden:{hidden}\\thsize:{hsize}\\tact:{act}\\tlr:{lr}\\topt:{opt}\\tepochs:{epochs}\\tscore:{score}\\n'.format( \n",
        "        batch=batch, hidden=hidden, hsize=hsize, act=act, lr=lr, opt=opt, epochs=epochs, score=score ) )"
      ],
      "metadata": {
        "id": "EK7KkDp4XXmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E05Ui0G9es1o"
      },
      "source": [
        "### TEST #1\n",
        "\n",
        "Start testing! The first test is the one with the 'default' parameters used in the previous practical session.\n",
        "\n",
        "▶▶**Describe the setting of the 'default' experiment**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶▶ **Run the model and evaluate on dev. Save the score for future comparison.**"
      ],
      "metadata": {
        "id": "RRCdktsEw3AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_loader, dev_loader, test_loader = load_data( x_train, y_train, x_dev, y_dev, x_test, y_test, batch_size=1 )"
      ],
      "metadata": {
        "id": "WV9IEMA8oxlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcGyjXbUoxx9"
      },
      "source": [
        "# Many choices here!\n",
        "VOCAB_SIZE = MAX_FEATURES\n",
        "input_dim = VOCAB_SIZE \n",
        "hidden_dim = 4\n",
        "output_dim = 2\n",
        "\n",
        "learning_rate = 0.1\n",
        "num_epochs = 5\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialization of the model\n",
        "# the model uses cross-entropy as a loss function, finds the best\n",
        "# parameters using stochastic gradient descent, and prints accuracy\n",
        "# metrics\n",
        "model_bow = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "optimizer = torch.optim.SGD( model_bow.parameters(), lr=learning_rate )\n",
        "\n",
        "# Train and evaluate\n",
        "# now we train the model by feeding it a batch of 1 training samples\n",
        "# at a time. When we get to the end of the training set, we repeat the\n",
        "# process, and we do this 5 times (epochs).\n",
        "train( model_bow, train_loader, optimizer )\n",
        "\n",
        "# We evaluate on dev set\n",
        "gold, pred = evaluate( model_bow, dev_loader )\n",
        "accuracy = accuracy_score( gold, pred )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_expe_settings( my_expe, batch=1, hidden=1, hsize=4, act='sigmoid', lr=0.1, opt='sgd', epochs=5, score=accuracy )"
      ],
      "metadata": {
        "id": "PwsL7C3XXly9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "169R-kzbTU4E"
      },
      "source": [
        "## 3. Exercises\n",
        "\n",
        "▶▶ **Now, try to change:**\n",
        "1. Batch size \n",
        "2. Max number of epochs (with best batch size)\n",
        "3. Size of the hidden layer\n",
        "4. Activation function\n",
        "5. Optimizer\n",
        "6. Learning rate\n",
        "7. Try with 1 additional layers \n",
        " \n",
        "\n",
        "How does this affect the loss and the performance of the model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.1 Batch size\n",
        "---\n",
        "\n",
        "Let's try with: 1, 10, 100, 1000"
      ],
      "metadata": {
        "id": "ayJIGZltUtlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TEST #2\n",
        "\n",
        "▶▶**Describe the setting of the second experiment**"
      ],
      "metadata": {
        "id": "NTaVQNUXVQcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "\n",
        "# Load data\n",
        "train_loader, dev_loader, test_loader = load_data( x_train, y_train, x_dev, y_dev, x_test, y_test, batch_size=batch_size )\n",
        "\n",
        "# Hyper-parameters\n",
        "hidden_dim = 4\n",
        "output_dim = 2\n",
        "learning_rate = 0.1\n",
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialization of the model\n",
        "model_bow = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "optimizer = torch.optim.SGD( model_bow.parameters(), lr=learning_rate )\n",
        "\n",
        "# Train and evaluate\n",
        "train( model_bow, train_loader, optimizer )\n",
        "gold, pred = evaluate( model_bow, dev_loader )\n",
        "accuracy = accuracy_score( gold, pred )\n",
        "\n",
        "write_expe_settings( my_expe, batch=batch_size, hidden=1, hsize=4, act='sigmoid', lr=0.1, opt='sgd', epochs=5, score=accuracy )"
      ],
      "metadata": {
        "id": "qPf2jBZ9VMTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TEST #3\n",
        "\n"
      ],
      "metadata": {
        "id": "arxB2-EScgCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5FAQEfiMVMWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TEST #4"
      ],
      "metadata": {
        "id": "Ag2f8LlF1GG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-uFA0zrn1Ga5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.2 Number of epochs\n",
        "---\n",
        "\n",
        "Try with: 5, 50"
      ],
      "metadata": {
        "id": "XejMdU5ocyBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TEST #5\n",
        "\n"
      ],
      "metadata": {
        "id": "vE_cC-bmdfVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PQreSe8pVMYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.3 Size of the hidden layer\n",
        "---\n",
        "\n",
        "Try with: 4, 16, 128, (5000 with 5 epochs max)"
      ],
      "metadata": {
        "id": "e-poMh3ndo2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.4 Activation function\n",
        "---\n",
        "Try with Sigmoid, Tanh, ReLU\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity"
      ],
      "metadata": {
        "id": "gpSfhvM8hMht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.5 Optimizer\n",
        "---\n",
        "Try SGD, RMSProp, Adam\n",
        "\n",
        "https://pytorch.org/docs/stable/optim.html#module-torch.optim"
      ],
      "metadata": {
        "id": "jqzTB4bfhNqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.6 Learning rate\n",
        "---\n",
        "Try with 0.1, 0.5, 0.001."
      ],
      "metadata": {
        "id": "SJxu3eDBjg7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 3.7 Number of hidden layers\n",
        "---\n",
        "\n",
        "Try with 1 and 2."
      ],
      "metadata": {
        "id": "IlyioqnpfeHt"
      }
    }
  ]
}